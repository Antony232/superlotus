# translation_manager.py - ç¿»è¯‘ç®¡ç†å™¨ï¼ˆç»Ÿä¸€åˆ«åé…ç½®+æ¸¸æˆçŠ¶æ€ç¿»è¯‘ï¼‰
import json
import re
import os
import logging
from typing import Dict, List, Tuple, Optional
from pathlib import Path
from utils.aliases_config import WARFRAME_PART_ALIASES, WEAPON_PART_ALIASES  # å¯¼å…¥ç»Ÿä¸€åˆ«å

# å¯¼å…¥æ¨¡ç³ŠåŒ¹é…å™¨ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
try:
    from utils.fuzzy_matcher import fuzzy_matcher
    FUZZY_MATCHER_AVAILABLE = True
except ImportError:
    FUZZY_MATCHER_AVAILABLE = False
    logging.getLogger(__name__).warning("âš ï¸ æ¨¡ç³ŠåŒ¹é…å™¨æœªæ‰¾åˆ°ï¼Œå°†ç¦ç”¨æ¨¡ç³ŠåŒ¹é…åŠŸèƒ½")

# ===================== ç²¾å‡†éƒ¨ä»¶å…³é”®è¯å®šä¹‰ =====================
# æå–æ‰€æœ‰ä¸­æ–‡éƒ¨ä»¶å…³é”®è¯ï¼ˆå»é‡ï¼‰
PART_KEYWORDS = []
# æå–æˆ˜ç”²éƒ¨ä»¶ä¸­æ–‡å…³é”®è¯
for aliases in WARFRAME_PART_ALIASES.values():
    for alias in aliases:
        if re.search(r'[\u4e00-\u9fff]', alias):
            PART_KEYWORDS.append(alias)
# æå–æ­¦å™¨éƒ¨ä»¶ä¸­æ–‡å…³é”®è¯
for aliases in WEAPON_PART_ALIASES.values():
    for alias in aliases:
        if re.search(r'[\u4e00-\u9fff]', alias):
            PART_KEYWORDS.append(alias)
# å»é‡å¹¶æ’åº
PART_KEYWORDS = list(set(PART_KEYWORDS))
PART_KEYWORDS.sort()


class TranslationManager:
    """ç¿»è¯‘ç®¡ç†å™¨ - ä¿®å¤Set slugåŒ¹é…ä¼˜å…ˆçº§é—®é¢˜"""

    def __init__(self, translation_file: str = "data/translations/item_translations.json"):
        self.translation_file = Path(translation_file)
        self.translations: Dict[str, str] = {}  # ä¸­æ–‡åˆ«åâ†’è‹±æ–‡slug
        self.reverse_translations: Dict[str, List[str]] = {}  # è‹±æ–‡slugâ†’ä¸­æ–‡åˆ«ååˆ—è¡¨
        self.set_slugs: List[str] = []  # æ‰€æœ‰_setç±»å‹çš„slug
        self.non_set_slugs: List[str] = []  # é_setç±»å‹çš„slug
        self.initialized = False
        self.logger = logging.getLogger(__name__)  # ä½¿ç”¨å®ä¾‹logger
        # ç¡®ä¿æ–‡ä»¶å­˜åœ¨
        if not self.translation_file.exists():
            self._create_default_translation_file()

    def _create_default_translation_file(self):
        """åˆ›å»ºé»˜è®¤ç¿»è¯‘æ–‡ä»¶ï¼ˆå…¼å®¹å¸­ç“¦ç¥ç›¾ç¤ºä¾‹ï¼‰"""
        default_data = {
            "silva_and_aegis_prime_set": [
                "å¸­ç“¦ & ç¥ç›¾ Prime ä¸€å¥—",
                "å¸­ç“¦ç¥ç›¾Primeä¸€å¥—",
                "å¸­ç“¦ & ç¥ç›¾ P ä¸€å¥—",
                "å¸­ç“¦ç¥ç›¾Pä¸€å¥—",
                "å¸­ç“¦ & ç¥ç›¾ Prime",
                "å¸­ç“¦ & ç¥ç›¾ P"
            ],
            "silva_and_aegis_prime_guard": [
                "å¸­ç“¦ & ç¥ç›¾ Prime æŠ¤æ‰‹",
                "å¸­ç“¦ç¥ç›¾PrimeæŠ¤æ‰‹",
                "å¸­ç“¦ & ç¥ç›¾ P æŠ¤æ‰‹",
                "å¸­ç“¦ç¥ç›¾PæŠ¤æ‰‹"
            ],
            "glaive_prime_set": [
                "æˆ˜åˆƒ Prime ä¸€å¥—",
                "æˆ˜åˆƒPrimeä¸€å¥—",
                "æˆ˜åˆƒ P ä¸€å¥—",
                "æˆ˜åˆƒPä¸€å¥—",
                "æˆ˜åˆƒ Prime",
                "æˆ˜åˆƒ P"
            ],
            "glaive_prime_blade": [
                "æˆ˜åˆƒ Prime åˆ€åˆƒ",
                "æˆ˜åˆƒPrimeåˆ€åˆƒ",
                "æˆ˜åˆƒ P åˆ€åˆƒ",
                "æˆ˜åˆƒPåˆ€åˆƒ"
            ]
        }
        with open(self.translation_file, 'w', encoding='utf-8') as f:
            json.dump(default_data, f, ensure_ascii=False, indent=2)
        self.logger.info(f"åˆ›å»ºé»˜è®¤ç¿»è¯‘æ–‡ä»¶: {self.translation_file}")

    def load_translations(self) -> bool:
        """åŠ è½½ç¿»è¯‘æ–‡ä»¶ - æ‹†åˆ†set/non-set slug"""
        try:
            if not self.translation_file.exists():
                self.logger.error(f"ç¿»è¯‘æ–‡ä»¶ä¸å­˜åœ¨: {self.translation_file}")
                return False
            with open(self.translation_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            # æ¸…ç©ºåŸæœ‰æ•°æ®
            self.translations.clear()
            self.reverse_translations.clear()
            self.set_slugs.clear()
            self.non_set_slugs.clear()
            # éå†æ‰€æœ‰slugï¼Œæ‹†åˆ†set/non-set
            for english_slug, chinese_list in data.items():
                # åˆ†ç±»slug
                if english_slug.endswith('_set'):
                    self.set_slugs.append(english_slug)
                else:
                    self.non_set_slugs.append(english_slug)
                # æ„å»ºåå‘æ˜ å°„ï¼ˆè‹±æ–‡â†’ä¸­æ–‡åˆ—è¡¨ï¼‰
                if isinstance(chinese_list, list):
                    self.reverse_translations[english_slug] = chinese_list
                else:
                    self.reverse_translations[english_slug] = [chinese_list]
                # æ„å»ºæ­£å‘æ˜ å°„ï¼ˆä¸­æ–‡åˆ«åâ†’è‹±æ–‡slugï¼‰
                for chinese_name in self.reverse_translations[english_slug]:
                    normalized_key = self._normalize_query(chinese_name)
                    self.translations[normalized_key] = english_slug.lower()
            self.initialized = True
            self.logger.debug(f"âœ… åŠ è½½ç¿»è¯‘å®Œæˆï¼š{len(self.translations)}é¡¹")
            return True
        except Exception as e:
            self.logger.error(f"åŠ è½½ç¿»è¯‘æ–‡ä»¶å¤±è´¥: {e}")
            return False

    def translate(self, query: str) -> Tuple[Optional[str], bool]:
        """ç¿»è¯‘æ ¸å¿ƒé€»è¾‘ - ä¿®å¤ï¼šå½“æŸ¥è¯¢ä¸åŒ…å«éƒ¨ä»¶å…³é”®è¯æ—¶ï¼Œä¼˜å…ˆåŒ¹é…æœ€çŸ­çš„Setåˆ«å"""
        if not self.initialized:
            self.load_translations()
        original_query = query.strip()
        normalized_query = self._normalize_query(original_query)
        self.logger.debug(f"å¼€å§‹ç¿»è¯‘: åŸå§‹='{original_query}', æ ‡å‡†åŒ–='{normalized_query}'")

        # æ­¥éª¤1ï¼šåˆ¤æ–­æ˜¯å¦åŒ…å«éƒ¨ä»¶å…³é”®è¯ï¼ˆç²¾å‡†åŒ¹é…ï¼‰
        has_part_keyword = any(keyword in original_query for keyword in PART_KEYWORDS)
        self.logger.debug(f"æ˜¯å¦åŒ…å«éƒ¨ä»¶å…³é”®è¯: {has_part_keyword}")
        
        # æ­¥éª¤2ï¼šå¦‚æœä¸åŒ…å«éƒ¨ä»¶å…³é”®è¯ï¼Œä¼˜å…ˆåŒ¹é…Set slugï¼ˆæŒ‰åˆ«åé•¿åº¦æ’åºï¼ŒçŸ­çš„ä¼˜å…ˆï¼‰
        if not has_part_keyword:
            set_match = self._match_set_slugs_best_fit(normalized_query, original_query)
            if set_match:
                self.logger.info(f"âœ… ä¼˜å…ˆåŒ¹é…Set slug: '{original_query}' -> '{set_match}'")
                return set_match.lower(), True

        # æ­¥éª¤3ï¼šå¦‚æœåŒ…å«éƒ¨ä»¶å…³é”®è¯æˆ–æ²¡æœ‰SetåŒ¹é…ï¼ŒåŒ¹é…éSet slug
        non_set_match = self._match_non_set_slugs(normalized_query, original_query)
        if non_set_match:
            self.logger.info(f"âœ… åŒ¹é…éSet slug: '{original_query}' -> '{non_set_match}'")
            return non_set_match.lower(), True

        # æ­¥éª¤4ï¼šæ¨¡ç³ŠåŒ¹é…/è‹±æ–‡è½¬æ¢ï¼ˆåŸæœ‰å…œåº•é€»è¾‘ï¼‰
        if FUZZY_MATCHER_AVAILABLE:
            fuzzy_slug, fuzzy_matched = fuzzy_matcher.match(original_query)
            if fuzzy_matched:
                self.logger.info(f"âœ… æ¨¡ç³ŠåŒ¹é…: '{original_query}' -> '{fuzzy_slug}'")
                return fuzzy_slug, True

        # æ­¥éª¤5ï¼šè‹±æ–‡æ ¼å¼è½¬æ¢
        if self._is_english_format(original_query):
            slug = self._convert_english_to_slug(original_query)
            self.logger.info(f"ğŸ“Œ è‹±æ–‡è½¬æ¢: '{original_query}' -> '{slug}'")
            return slug, False

        # æ— åŒ¹é…ç»“æœ
        self.logger.warning(f"âŒ æœªæ‰¾åˆ°åŒ¹é…: '{original_query}'")
        return None, False

    def _match_set_slugs_best_fit(self, normalized_query: str, original_query: str) -> Optional[str]:
        """ä¸“é—¨åŒ¹é…Set slugï¼ŒæŒ‰åˆ«åé•¿åº¦æ’åºï¼Œæœ€çŸ­çš„ä¼˜å…ˆï¼ˆæé«˜ç²¾ç¡®åº¦ï¼‰"""
        # æ”¶é›†æ‰€æœ‰å¯èƒ½çš„SetåŒ¹é…
        possible_matches = []

        for set_slug in self.set_slugs:
            set_aliases = self.reverse_translations.get(set_slug, [])
            for alias in set_aliases:
                normalized_alias = self._normalize_query(alias)

                # 1. å®Œå…¨åŒ¹é…ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
                if normalized_query == normalized_alias:
                    self.logger.debug(f"å®Œå…¨åŒ¹é…Set slug: '{normalized_query}' == '{normalized_alias}' -> '{set_slug}'")
                    return set_slug

                # 2. æŸ¥è¯¢åŒ…å«åˆ«åæˆ–åˆ«ååŒ…å«æŸ¥è¯¢
                if normalized_query in normalized_alias or normalized_alias in normalized_query:
                    # è®°å½•åŒ¹é…åº¦ï¼ˆåˆ«åé•¿åº¦è¶ŠçŸ­ï¼ŒåŒ¹é…åº¦è¶Šé«˜ï¼‰
                    match_info = {
                        'slug': set_slug,
                        'alias_length': len(alias),
                        'normalized_alias': normalized_alias
                    }
                    possible_matches.append(match_info)

        # å¦‚æœæœ‰å¤šä¸ªå¯èƒ½çš„åŒ¹é…ï¼ŒæŒ‰åˆ«åé•¿åº¦æ’åºï¼ˆæœ€çŸ­çš„ä¼˜å…ˆï¼‰
        if possible_matches:
            possible_matches.sort(key=lambda x: x['alias_length'])
            best_match = possible_matches[0]['slug']
            self.logger.debug(f"ä»{len(possible_matches)}ä¸ªSetåŒ¹é…ä¸­é€‰æ‹©æœ€çŸ­åˆ«å: '{best_match}'")
            return best_match

        return None

    def _match_non_set_slugs(self, normalized_query: str, original_query: str) -> Optional[str]:
        """åŒ¹é…éSet slug - ä¿®å¤åŒ¹é…é€»è¾‘ï¼Œä¼˜å…ˆå®Œå…¨åŒ¹é…"""
        # 1. é¦–å…ˆå°è¯•å®Œå…¨åŒ¹é…
        for non_set_slug in self.non_set_slugs:
            non_set_aliases = self.reverse_translations.get(non_set_slug, [])
            for alias in non_set_aliases:
                normalized_alias = self._normalize_query(alias)
                if normalized_query == normalized_alias:
                    self.logger.debug(f"å®Œå…¨åŒ¹é…éSet slug: '{normalized_query}' == '{normalized_alias}' -> '{non_set_slug}'")
                    return non_set_slug

        # 2. å¦‚æœæ²¡æœ‰å®Œå…¨åŒ¹é…ï¼Œå†å°è¯•éƒ¨åˆ†åŒ¹é…
        for non_set_slug in self.non_set_slugs:
            non_set_aliases = self.reverse_translations.get(non_set_slug, [])
            for alias in non_set_aliases:
                normalized_alias = self._normalize_query(alias)
                if normalized_query in normalized_alias or normalized_alias in normalized_query:
                    # æ£€æŸ¥æ˜¯å¦åŒ…å«éƒ¨ä»¶å…³é”®è¯ï¼Œç¡®ä¿åŒ¹é…æ­£ç¡®
                    if any(keyword in original_query for keyword in PART_KEYWORDS):
                        return non_set_slug

        return None

    # å·¥å…·æ–¹æ³•ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
    def _normalize_query(self, query: str) -> str:
        """æ ‡å‡†åŒ–æŸ¥è¯¢è¯ï¼šå»ç©ºæ ¼ã€å°å†™ã€ç»Ÿä¸€P/Prime"""
        return query.replace(' ', '').replace('_', '').lower().replace('prime', 'p')

    def _is_english_format(self, text: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºè‹±æ–‡è¾“å…¥"""
        return not bool(re.search(r'[\u4e00-\u9fff]', text)) and bool(re.search(r'[a-zA-Z]', text))

    def _convert_english_to_slug(self, query: str) -> str:
        """å°†è‹±æ–‡è½¬æ¢ä¸ºslugæ ¼å¼"""
        query_lower = query.lower()
        query_clean = re.sub(r'[^\w\s]', ' ', query_lower)
        query_clean = re.sub(r'\s+', ' ', query_clean).strip()
        return query_clean.replace(' ', '_')

    def get_chinese_names(self, english_slug: str) -> List[str]:
        """è·å–è‹±æ–‡slugå¯¹åº”çš„ä¸­æ–‡åˆ«ååˆ—è¡¨"""
        return self.reverse_translations.get(english_slug, [])

    def list_part_keywords(self) -> List[str]:
        """è¿”å›æ‰€æœ‰éƒ¨ä»¶å…³é”®è¯åˆ—è¡¨ï¼ˆç”¨äºè°ƒè¯•ï¼‰"""
        return PART_KEYWORDS


# ===================== æ¸¸æˆçŠ¶æ€ç¿»è¯‘å™¨ï¼ˆåˆå¹¶è‡ª game_status_translator.pyï¼‰=====================
class GameStatusTranslator:
    """æ¸¸æˆçŠ¶æ€ç¿»è¯‘å™¨ - ç¿»è¯‘èŠ‚ç‚¹ã€ä»»åŠ¡ç±»å‹ã€æ´¾ç³»ç­‰æ¸¸æˆæ•°æ®"""
    def __init__(self):
        self.sol_nodes: Dict = {}
        self.languages: Dict = {}
        self.loaded = False
        self.logger = logging.getLogger(__name__)

    def load_translations(self):
        """åŠ è½½ç¿»è¯‘æ–‡ä»¶"""
        try:
            # å°è¯•å¤šç§å¯èƒ½çš„è·¯å¾„æŸ¥æ‰¾æ–‡ä»¶
            possible_paths = [
                'data/game_data/solNodes.json',  # æ–°è·¯å¾„
                'solNodes.json',  # å½“å‰ç›®å½•
                './solNodes.json',
                '../solNodes.json',
                './game_status_data/solNodes.json',
                os.path.join(os.path.dirname(os.path.abspath(__file__)), 'solNodes.json'),
                os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 'solNodes.json'),
            ]

            sol_nodes_found = False
            languages_found = False

            # åŠ è½½èŠ‚ç‚¹æ•°æ®
            for path in possible_paths:
                if os.path.exists(path):
                    with open(path, 'r', encoding='utf-8') as f:
                        self.sol_nodes = json.load(f)
                    self.logger.info(f"âœ… æˆåŠŸä» {path} åŠ è½½èŠ‚ç‚¹æ•°æ®")
                    sol_nodes_found = True
                    break

            if not sol_nodes_found:
                self.logger.warning("âš ï¸  æœªæ‰¾åˆ°solNodes.jsonæ–‡ä»¶ï¼ŒèŠ‚ç‚¹ç¿»è¯‘åŠŸèƒ½å°†å—é™")
                self.sol_nodes = {}

            # åŠ è½½è¯­è¨€æ•°æ®
            for path in possible_paths:
                path_lang = path.replace('solNodes.json', 'zh.json')
                path_lang = path_lang.replace('game_data', 'translations')  # ä¿®æ­£zh.jsonçš„è·¯å¾„
                if os.path.exists(path_lang):
                    with open(path_lang, 'r', encoding='utf-8') as f:
                        self.languages = json.load(f)
                    self.logger.info(f"âœ… æˆåŠŸä» {path_lang} åŠ è½½è¯­è¨€æ•°æ®")
                    languages_found = True
                    break

            if not languages_found:
                self.logger.warning("âš ï¸  æœªæ‰¾åˆ°languages.jsonæ–‡ä»¶ï¼Œéƒ¨åˆ†ç¿»è¯‘åŠŸèƒ½å°†å—é™")
                self.languages = {}

            self.loaded = True
            return True
        except Exception as e:
            self.logger.error(f"âŒ åŠ è½½ç¿»è¯‘æ–‡ä»¶å¤±è´¥: {e}")
            self.sol_nodes = {}
            self.languages = {}
            self.loaded = True
            return False

    def translate_node(self, node_path: str) -> str:
        """ç¿»è¯‘èŠ‚ç‚¹è·¯å¾„ä¸ºä¸­æ–‡åç§°"""
        if not self.loaded or not self.sol_nodes:
            return node_path

        # 1. å¦‚æœèŠ‚ç‚¹è·¯å¾„æ˜¯å®Œæ•´çš„URLè·¯å¾„
        if '/' in node_path:
            parts = node_path.split('/')
            node_key = parts[-1]
            if node_key in self.sol_nodes:
                english_name = self.sol_nodes[node_key].get('value', node_key)
                return self._translate_text(english_name)

        # 2. å¦‚æœèŠ‚ç‚¹è·¯å¾„å°±æ˜¯èŠ‚ç‚¹ID (å¦‚ SolNode100)
        if node_path in self.sol_nodes:
            english_name = self.sol_nodes[node_path].get('value', node_path)
            return self._translate_text(english_name)

        # 3. å°è¯•ä»è·¯å¾„ä¸­æå–èŠ‚ç‚¹ID
        match = re.search(r'(SolNode\d+)', node_path)
        if match and match.group(1) in self.sol_nodes:
            node_key = match.group(1)
            english_name = self.sol_nodes[node_key].get('value', node_path)
            return self._translate_text(english_name)

        # 4. ç›´æ¥ç¿»è¯‘æ•´ä¸ªè·¯å¾„
        return self._translate_text(node_path)

    def translate_mission_type(self, mission_type: str) -> str:
        """ç¿»è¯‘ä»»åŠ¡ç±»å‹"""
        if not self.loaded:
            return mission_type

        mission_translations = {
            'MT_EXTERMINATION': 'æ­¼ç­',
            'MT_SURVIVAL': 'ç”Ÿå­˜',
            'MT_DEFENSE': 'é˜²å¾¡',
            'MT_MOBILE_DEFENSE': 'ç§»åŠ¨é˜²å¾¡',
            'MT_CAPTURE': 'æ•è·',
            'MT_RESCUE': 'æ•‘æ´',
            'MT_SPY': 'é—´è°',
            'MT_SABOTAGE': 'ç ´å',
            'MT_ASSASSINATION': 'åˆºæ€',
            'MT_INTEL': 'é—´è°',
            'MT_TERRITORY': 'æ‹¦æˆª',
            'MT_ALCHEMY': 'å…ƒç´ è½¬æ¢',
            'MT_ARTIFACT': 'ä¸­æ–­',
            'MT_EXCAVATE': 'æŒ–æ˜',
            'MT_VOID_CASCADE': 'è™šç©ºè¦†æ¶Œ',
            'MT_RETRIEVAL': 'åŠ«æŒ',
            'MT_HIVE':'æ¸…å·¢',
            'MT_CORRUPTION':'è™šç©ºæ´ªæµ',
            'MT_ASSAULT':'å¼ºè¢­',
            'MT_ENDLESS_CAPTURE': 'ä¼ æ‰¿ç§æ”¶å‰²'
        }

        if mission_type in mission_translations:
            return mission_translations[mission_type]

        return self._translate_text(mission_type)

    def translate_faction(self, faction: str) -> str:
        """ç¿»è¯‘æ´¾ç³»"""
        if not self.loaded:
            return faction

        faction_translations = {
            'FC_GRINEER': 'Grineer',
            'FC_CORPUS': 'Corpus',
            'FC_INFESTATION': 'Infested',
            'FC_OROKIN': 'Orokin',
            'FC_CORRUPTED': 'å •è½è€…'
        }

        if faction in faction_translations:
            return faction_translations[faction]

        return self._translate_text(faction)

    def _translate_text(self, english_text: str) -> str:
        """ä»languages.jsonè·å–ä¸­æ–‡ç¿»è¯‘"""
        if not english_text or not self.languages:
            return english_text

        # å°è¯•ç›´æ¥åŒ¹é…
        if english_text in self.languages:
            translation_data = self.languages[english_text]
            if isinstance(translation_data, dict):
                return translation_data.get('zh', english_text)
            elif isinstance(translation_data, str):
                return translation_data

        # å¦‚æœæ²¡æœ‰ç›´æ¥åŒ¹é…ï¼Œå°è¯•åœ¨å€¼ä¸­æœç´¢
        for key, value in self.languages.items():
            if isinstance(value, dict) and value.get('en') == english_text:
                return value.get('zh', english_text)

        # ç®€å•çš„æ˜Ÿçƒåç§°æ˜ å°„
        planet_map = {
            'Earth': 'åœ°çƒ', 'Venus': 'é‡‘æ˜Ÿ', 'Mercury': 'æ°´æ˜Ÿ',
            'Mars': 'ç«æ˜Ÿ', 'Deimos': 'ç«å«äºŒ', 'Phobos': 'ç«å«ä¸€',
            'Ceres': 'è°·ç¥æ˜Ÿ', 'Jupiter': 'æœ¨æ˜Ÿ', 'Europa': 'æœ¨å«äºŒ',
            'Saturn': 'åœŸæ˜Ÿ', 'Uranus': 'å¤©ç‹æ˜Ÿ', 'Neptune': 'æµ·ç‹æ˜Ÿ',
            'Pluto': 'å†¥ç‹æ˜Ÿ', 'Sedna': 'èµ›å¾·å¨œ', 'Eris': 'é˜‹ç¥æ˜Ÿ',
            'Void': 'è™šç©º', 'Kuva Fortress': 'èµ¤æ¯’è¦å¡',
            'Lua': 'æœˆçƒ', 'Zariman': 'æ‰é‡Œæ›¼'
        }

        for eng, chi in planet_map.items():
            if english_text.startswith(eng):
                return english_text.replace(eng, chi)

        return english_text

    def translate_syndicate(self, syndicate_tag: str) -> str:
        """ç¿»è¯‘æ´¾ç³»æ ‡ç­¾"""
        syndicate_map = {
            'CetusSyndicate': 'å¤œçµå¹³é‡',
            'SolarisSyndicate': 'å¥¥å¸ƒå±±è°·',
            'EntratiSyndicate': 'é­”èƒä¹‹å¢ƒ'
        }
        return syndicate_map.get(syndicate_tag, syndicate_tag)

    def translate_text(self, english_text: str) -> str:
        """é€šç”¨ç¿»è¯‘æ–‡æœ¬ï¼ˆå…¼å®¹ä¹‹å‰çš„è°ƒç”¨ï¼‰"""
        return self._translate_text(english_text)


# ===================== å…¨å±€å®ä¾‹ =====================
# ç‰©å“ç¿»è¯‘ç®¡ç†å™¨
translation_manager = TranslationManager()

# æ¸¸æˆçŠ¶æ€ç¿»è¯‘å™¨
game_translator = GameStatusTranslator()
translator = game_translator  # å…¼å®¹æ—§ä»£ç åˆ«å


# è°ƒè¯•ç”¨ï¼šæ‰“å°éƒ¨ä»¶å…³é”®è¯
if __name__ == "__main__":
    print("=== éƒ¨ä»¶å…³é”®è¯åˆ—è¡¨ ===")
    for idx, keyword in enumerate(translation_manager.list_part_keywords(), 1):
        print(f"{idx}. {keyword}")